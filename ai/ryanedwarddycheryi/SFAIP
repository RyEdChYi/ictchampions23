# importing various math and graphing modules
import numpy as np                # importing math modules
import matplotlib.pyplot as plt   # importing graphing modules
import seaborn as sns             # importing addons to the math modules
import pandas as pd
%matplotlib inline
# creating classes for the data to go into

column_features = ['Forehead_width','Cheeks_width','Jawline_length','Face_length','Face_Type']
from google.colab import drive
drive.mount('/content/drive')
# showing the first 5 rows of data from the .csv document

df.head(5)
# printing the number of faces with a face type == square
face_type_count = len(df[df["Face_Type"]=="square"])

print(face_type_count)
# plotting down the data into the graphs seen below

sns.pairplot(df, hue='Face_Type')
# saves X as all of the data from the 1st to 4th column and Y as the data from the 5th column

data = df.values    # defining 'data' as the values from df
X = data[:,0:4]     # defining X as values from 'data'
Y = data[:,4]       # defining Y as more values from 'data'
Y_Data = np.array([np.average(X[:, i][Y==j].astype('float32')) for i in range (X.shape[1]) for j in (np.unique(Y))])    # creating a dataset from X and Y for each element in the respective variables
Y_Data_reshaped = Y_Data.reshape(4,6)                                                                                   # changing the rows/ columns of the data provided
Y_Data_reshaped = np.swapaxes(Y_Data_reshaped, 0, 1)
X_axis = np.arange(len(column_features)-1)
width = 0.1
# plotting a bar graph thet compares the various features of the specific face shape

plt.bar(X_axis, Y_Data_reshaped[0], width, label = 'square')
plt.bar(X_axis+width, Y_Data_reshaped[1], width, label = 'diamond')
plt.bar(X_axis+width*2, Y_Data_reshaped[2], width, label = 'triangle')
plt.bar(X_axis+width*3, Y_Data_reshaped[2], width, label = 'oblong')
plt.bar(X_axis+width*4, Y_Data_reshaped[2], width, label = 'oval')
plt.bar(X_axis+width*5, Y_Data_reshaped[2], width, label = 'heart')
plt.xticks(X_axis, column_features[:4])
plt.xlabel("Features")
plt.ylabel("Values")
plt.legend(bbox_to_anchor=(1.3,1))
plt.show()
# start to train the AI

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)   # splits the data 70:30 for training and testing
# using a Support Vector Machine to train the AI

from sklearn.svm import SVC
svn = SVC()
svn.fit(X_train, y_train)

# you can consider a Decision Tree Classifier
# from sklearn.tree import DecisionTreeClassifier

# dt = DecisionTreeClassifier()                     # save decision tree
# if you're using decision tree, you'll just need to change the code below from "svn" to "dt"
# creating the predictions from the testing data that the AI has made

predictions = svn.predict(X_test)

# what does "accuracy_score" does and what does it mean?
# how accurate the predictions of the AI are from a score of 0 - 1

from sklearn.metrics import accuracy_score
accuracy_score(y_test, predictions)
# what and how the AI has done in terms of successfully classifying data

from sklearn.metrics import classification_report
print(classification_report(y_test, predictions))
